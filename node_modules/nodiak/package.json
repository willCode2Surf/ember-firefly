{
  "name": "nodiak",
  "version": "0.0.9",
  "description": "Nodiak is a Node.js client for the Riak Distributed Database",
  "author": {
    "name": "Nathan Aschbacher",
    "email": "nathan@coradine.com"
  },
  "contributors": [
    {
      "name": "Nathan Aschbacher",
      "email": "nathan@coradine.com"
    }
  ],
  "license": "MIT",
  "main": "index.js",
  "scripts": {
    "test": "./node_modules/.bin/mocha"
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/Coradine/nodiak.git"
  },
  "dependencies": {
    "deepmerge": ">=0.2.5",
    "async": ">=0.1.22",
    "trustfund": ">=0.1.0"
  },
  "devDependencies": {
    "mocha": "*",
    "should": "*"
  },
  "keywords": [
    "riak",
    "nodiak",
    "coradine",
    "basho"
  ],
  "engines": {
    "node": ">=0.8.x"
  },
  "readme": "# Overview\n\nNodiak is a node.js client to [the Riak distributed database](http://basho.com/products/riak-overview/).  The focus of Nodiak is to provide a client that mimics some of the patterns and functionality of Basho's official clients for other languages while still taking advantage of the benefits of asynchronous patterns that can be easily implemented in node.js.\n\nNodiak's design is split across two general concepts.  The base client, which handles the base Riak HTTP API operations, and useful higher-level abstractions (Bucket and RObject) that build on the base client functionality to make Riak easier to work with.\n\n> ***NOTE:*** \n\n>While the base client's methods are available in the event you need them. The \\_bucket and \\_object namespace won't be detailed in this document because you should use the convience classes and abstratctions whenever possible.\n\n# Features\n\n* HTTP and HTTPS connections.\n* Automatic exponential-backoff retries.\n* Cluster info operations.\n* Bulk/Batch object operations (Get, Save, Delete).\n* Sibling notification.\n* Parallel async and 'at once' sibling fetching.\n* Sibling resolution and auto-resolution support (default: client-side LWW).\n* MapReduce phase chaining.\n* Ad-hoc Javascript and Erlang MapReduce functions.\n* Riak Search and Riak 2i support.\n* Evented stream results handling.\n* Easy multiple cluster support.\n\n# Installation\n\n    $ npm install nodiak\n\n# API\n\n> ***NOTE:*** significant search and streaming changes occurred in >= 0.0.7\n\nAll methods that communicate with Riak take a callback function as their last parameter.  In many cases they're optional if you don't care about handling the results, so you can sort of fire-and-forget requests to Riak. In the case of operations which can provide streaming results, the callback is simply dropped from the primary method call, and the `.stream()` method is appeneded.  [See details below](#-streaming-callback-form).\n\n#####standard callback form\n\n```javascript\nbucket.objects.get(array_of_keys, function(err, objs){})\n```\n\nThe argument signature of the callback for non-streaming results is always `callback(error, result)`.  Where error will always be either `null` when there was no error, or an instance of `Error`, or any array of `Error`s with details of the errors when they occur.  The `result` varies depending on the API call.  See the [detailed API documentation](#api) below for details.\n\n#####streaming callback form\n\n```javascript\nbucket.objects.get(array_of_keys).stream(function(event_emitter){})\n```\n\nFor streaming results the callback sent into the `.stream()` function gets an instance of `EventEmitter` passed to it, and this emitter fires `'data'`, `'error'`, and `'end'` events. \n\n#Getting Started\n \n####require('nodiak').getClient( _[backend], [host], [port], [defaults]_ );\n###### // get client instance (defaults to HTTP backend on localhost:8098)\n\n```javascript\nvar riak = require('nodiak').getClient();\n```\n\nw/ custom backend, host, and port:\n\n```javascript\nvar riak = require('nodiak').getClient('https', '10.0.0.2', 8443);\n```\n\nw/ non-default client settings, such as resource locations, maxSockets value, mime decoders/encoders, etc:\n\n```javascript\nvar my_defaults = {\n\tconnection: { maxSockets: 50 },\n\tresources: {\n        riak_kv_wm_mapred: \"/mapreduce\",\n        riak_kv_wm_stats: \"/statistics\",\n        riak_solr_indexer_wm: \"/search\"\n\t}\n}\n\n// the 'defaults' object should always be the last.\nvar riak = require('nodiak').getClient('https', my_defaults); \n```\n\nFor multiple-clusters just create several instances:\n\n```javascript\nvar cache = require('nodiak').getClient('https', '10.0.0.2', 8443);\nvar sessions = require('nodiak').getClient('http', '192.168.2.20', 8098);\nvar db = require('nodiak').getClient();\n```\n\n##Cluster info and status:\n####.ping( _callback_ );\n###### //  check that you can reach Riak\n\n```javascript\nriak.ping(function(err, response) {\n\tconsole.log(response);\n});\n```\n> ```\n'OK'\n> ```\n\n####.stats( _callback_ );\n###### //  get current stats from Riak\n\n```javascript\nriak.stats(function(err, response) {\n\tconsole.log(response); // prints the stats provided by the 'riak_kv_wm_stats' resource.\n});\n```\n> ```\n{ vnode_gets: 0,\n  ring_num_partitions: 64,\n  storage_backend: 'riak_kv_eleveldb_backend',\n  ... }\n> ```\n\n####.resources( _callback_ );\n###### // ask Riak for its current resource endpoints.\n\n> ***NOTE:*** \n\n>These are what your Riak install is using, not necessarily what the\nnodiak client is using.  If you want to synchronize these values, you'll\nhave to manage that yourself.  getClient() -> .resources(result) ->\ngetClient(result), or something similar. \n\n```javascript\nriak.resources(function(err, response) {\n\tconsole.log(response);\n});\n```\n> ```\n{ riak_kv_wm_buckets: '/riak',\n  riak_kv_wm_index: '/buckets',\n  riak_kv_wm_keylist: '/buckets',\n  riak_kv_wm_link_walker: '/riak',\n  riak_kv_wm_mapred: '/mapred',\n  ... }\n> ```\n\n\n# Bucket Operations:\n##Bucket instance attributes\n* ####.name \n>The name of the bucket in Riak as a `String`.\n* ####.props\n>An `Object` containing the Riak [bucket properties](http://wiki.basho.com/HTTP-Set-Bucket-Properties.html).  Defaults to `{}`. \n* ####.resolver\n>The `Function` used to do sibling resolution on `.object.get()` requests.  Defaults to `Bucket.siblingLastWriteWins` ([see here](#sibling-auto-resolution)).\n* ####.getSiblingsSync\n>Controls whether or not fetching siblings happens using parallel async requests or as one big _'multipart/mixed'_ to be parsed at once. Defaults to `false`.\n* ####.client\n>An instance of the underlying backend client that handles communication with Riak.  Is set to the client that created the `Bucket` instance with `client.bucket()`.\n\n##Bucket instance methods\n####_client_.bucket( _name_ );\n###### // factory method on the client that returns an instance of a Bucket object.\n\n```javascript\nvar user_bucket = riak.bucket('users');\nuser_bucket.objects.all(function(err, r_objs) {\n    console.log(r_objs);\n});\n```\n>```\n[[Object], [Object], [Object]]  // Array of RObjects\n>```\n\nw/ a simple chaining pattern:\n\n```javascript\nriak.bucket('users').objects.all(function(err, r_objs) {\n    console.log(r_objs);\n});\n```\n>```\n[[Object], [Object], [Object]]  // Array of RObjects\n>```\n\n####Bucket.getProps( _[callback]_ );\n###### // update the Bucket instance with its bucket props from Riak\n\n```javascript\nvar user_bucket = riak.bucket('users');\n\nuser_bucket.getProps(function(err, props) {\n\tconsole.log(users.props);\n});\n```\n\n>```\n{ name: 'users',\n  allow_mult: false,\n  basic_quorum: false,\n  big_vclock: 50,\n  ... }\n>```\n\n####Bucket.saveProps( _[merge], [callback]_ );\n###### // save updated bucket properties back to Riak.\n\n```javascript\nvar users = riak.bucket('users');\n\nusers.props.n_val = 2;\nusers.props.allow_mult = true;\nusers.props.last_write_wins = false;\n\nusers.saveProps(true, function(err, props) {\n\tconsole.log(users.props);\n});\n```\n\n>```\n{ name: 'users',\n  allow_mult: true,\n  last_write_wins: false,\n  n_val: 2,\n  ... }\n>```\n\nThe optional `merge` argument is a boolean indicating wether to first get the bucket's properties from Riak and merge your updates with them, or to simply write your updates to Riak right away. This defaults to `true` and is helpful in preventing you from obliterating things like pre and post-commit hooks defined on the bucket.\n\n####Bucket.object.new( _key, [data], [metadata]_ )\n###### // factory method that returns a new instance of an RObject.\n\n```javascript\nvar my_robj = riak.bucket('users').object.new('some_key', { store: 'this thing'}, { vclock: 'aBcDE10fgH92'});\n```\n\nIt's important to understand that this new object ***has not*** been read from or written to Riak at this point.  If you know this key already exists in, or you want to refresh its data from, Riak, then you can 'hydrate' it using the RObject's `.fetch()` method.\n\n####Bucket.object.exists( _key, callback_ )\n###### // checks if an object exists in Riak\n\n```javascript\nriak.bucket('users').object.exists('some_key', function(err, result) {\n    console.log(result);\n});\n```\n\n`result` will be either `true` or `false`.\n\n####Bucket.objects.get( _keys, [options], [resolver_fn, callback]_ )\n###### // get one or more objects from Riak as RObjects.\n\nThis method can take a single key or an `Array` of keys as input.  Each request happens asynchronously in parallel.  The optional `options` parameter is an object that can contain [Riak query parameters](http://wiki.basho.com/HTTP-Fetch-Object.html).  Additionally, the optional `resolver_fn` parameter allows you to pass in a custom sibling resolution function in the event any siblings are found.\n\n```javascript\nvar my_keys = ['me', 'myself', 'andI'];\n\nriak.bucket('users').objects.get(my_keys, { r: 1 }, function(errs, objs) {\n    console.log(objs);\n    console.warn(errs);\n});\n```\n\nBecause I passed in an `Array` of keys the resulting `objs` value will be an `Array` of the resuling `RObject`s.  If the request produced errors then the `err` value will be either a single `Error` or an `Array` of `Error`'s for each that occurred.  `Error.data` will contain the _key_ for the failed request.\n\n> ***NOTE:*** \n\n>By default nodiak fetches object siblings using parallel async GET requests for each sibling.  This behavior can be overridden by setting the `.getSiblingsSync` property on the `Bucket` instance to `true`.  This will cause nodiak to get all the siblings as a single large *'multipart/mixed'* document and parse the contents.  Further details in the [Sibling Auto-Resolution](#sibling-auto-resolution) section.\n\n####Bucket.objects.get( _keys, [options]_ ).stream( _[resolver_fn], callback_ )\n###### // get one or more objects from Riak as a stream of RObjects.\n\nAll the same details apply here as in the standard `Bucket.objects.get()` method, except to signal that you want to stream the objects back from Riak you drop the callback **and** the resolver from `.get()`, place them in `.stream()`, and attach your listeners to the parameter passed to the callback.\n\n```javascript\nvar my_keys = ['me', 'myself', 'andI'];\n\nriak.bucket('users').objects.get(my_keys, { r: 1 }).stream(function(results) {\n    results.on('data', function(obj) {\n        console.log(obj);\n    });\n    \n    results.on('error', function(err) {\n        console.warn(err);\n    });\n    \n    results.on('end', function() {\n        // do something else after we're all done getting the objects.\n    });\n});\n```\n\n####Bucket.objects.save( _r_objects, [callback]_)\n###### // save one or more RObjects to Riak.\n\nYou can pass a single `RObject` or an `Array` of `RObject`s into this method.  Just like with the `.get()` and `.delete()` methods, each save request will happen asynchronously in parallel.\n\n```javascript\nvar things_to_save = [];\n\nfor(var i = 0; i < 5; i++) {\n    var robj = riak.bucket('users').objects.new('me'+i, { about_me: \"I write software.\" });\n    robj.addMeta('extra_info', 'data goes up in here');\n    robj.addToIndex('numbers_i_like', [20, 3, 6]);\n    things_to_save.push(robj);\n}\n\nriak.bucket('users').objects.save(objs, function(errs, objs) {\n    console.log(objs);\n    console.warn(errs);\n});\n```\n\n`objs` will be an `Array` of the successfully saved `RObjects`, and `errs` will be single or multiple `Errors` for failed save requests.  `Error.data` will be the RObject that failed to save to Riak.\n\n####Bucket.objects.save( _r_objects_ ).stream( _callback_ )\n###### // save one or more RObjects to Riak and get streamed results.\n\nAll the same details apply here as in the standard `Bucket.objects.save()` method, except to signal that you want to stream the result notifications back from Riak you drop the callback from `.save()`, place it in `.stream()`, and attach your listeners to the parameter passed to the callback.\n\n```javascript\nvar things_to_save = [];\n\nfor(var i = 0; i < 5; i++) {\n    var robj = riak.bucket('users').objects.new('me'+i, { about_me: \"I write software.\" });\n    robj.addMeta('extra_info', 'data goes up in here');\n    robj.addToIndex('numbers_i_like', [20, 3, 6]);\n    things_to_save.push(robj);\n}\n\nriak.bucket('users').objects.save(objs).stream(function(results) {\n    results.on('data', function(obj) {\n        console.log(obj);\n    });\n    \n    results.on('error', function(err) {\n        console.warn(err);\n    });\n    \n    results.on('end', function() {\n        // do something else after we're all done getting the objects.\n    });\n});\n```\n\n####Bucket.objects.delete( _r_objects, [callback]_ )\n###### // delete one or more RObjects from Riak.\n\nYou can pass a single `RObject` or an `Array` of `RObject`s into this method.  Just like with the `.get()` and `.save()` methods, each delete request will happen asynchronously in parallel.\n\n```javascript\nriak.bucket('users').objects.delete(array_of_robjs, function(errs, objs) {\n    console.log(objs);\n    console.warn(errs);\n});\n```\n\n`objs` will be an `Array` of the successfully deleted `RObjects`, and `errs` will be single or multiple `Errors` for failed delete requests.  `Error.data` will be the RObject that failed to be deleted from Riak.\n\n####Bucket.objects.delete( _r_objects_ ).stream( _callback_ )\n###### // delete one or more RObjects to Riak and get streamed results.\n\nAll the same details apply here as in the standard `Bucket.objects.delete()` method, except to signal that you want to stream the result notifications back from Riak you drop the callback from `.save()`, place it in `.stream()`, and attach your listeners to the parameter passed to the callback.\n\n```javascript\nriak.bucket('users').objects.delete(array_of_robjs).stream(function(results) {\n    results.on('data', function(obj) {\n        console.log(obj);\n    });\n    \n    results.on('error', function(err) {\n        console.warn(err);\n    });\n    \n    results.on('end', function() {\n        // do something else after we're all done deleting the objects.\n    });\n});\n```\n\n####Bucket.objects.all( _callback_ )\n###### // traverse a bucket to get all the RObjects in it.  DO _NOT_ USE IN PRODUCTION, okay? OK.\n\nThis method is the equivalent of the dreaded _list keys_ operation… _except even more deadly!_  This will not only perform a list keys on the bucket, but it will also `.get()` every single key it finds.  Use this only for development/testing purposes.  **If you think you need this in production, you're doing it wrong!**\n\n```javascript\nriak.bucket('users').objects.all(function(err, objs) {\n    console.warn(\"I BETTER NOT BE IN PRODUCTION\");\n    console.warn(\"NO, SERIOUSLY.\");\n    \n    console.log(objs);\n});\n```\n\n#RObject Operations\n##RObject instance attributes\n* ####.bucket\n>The `Bucket` instance that created this `RObject`.\n\n* ####.key\n>The key for this object in Riak.  Defaults to `null`, which will cause Riak to generate a key when saving the RObject.\n\n* ####.data\n>The data stored in Riak for this object.  Defaults to `{}`.\n\n* ####.metadata\n>The metadata on the object stored in Riak, ie. vclock, content_type, last_modified, etc.  Defaults to `{}`.  A fully populated `metadata` object might look like this:\n>>```javascript\n{\n    vclock: 'a85hYGBgzGDKBVIcR4M2cgcY8xzJYEpkzGNlcJ708CRfFgA=',\n    meta: {\n        info: 'you might want to know',\n        extra: 'stuff you can store here'\n    },\n    index: {\n        words: {\n            bin: ['other', 'that', 'the', 'this']\n        },\n        mynumbers: {\n            int: ['5', '37', '4234']\n        }\n    },\n    link: '</buckets/test>; rel=\"up\"',\n    last_modified: 'Thu, 04 Oct 2012 04:53:23 GMT',\n    etag: '\"BTYdk4S0eisdrIYeA1OkM\"',\n    content_type: 'application/json',\n    status_code: 200\n}\n>>```\n\n* ####.options\n>An `Object` for setting [Riak query parameters](http://wiki.basho.com/HTTP-Fetch-Object.html).  Defaults to `{}`.\n\n* ####.siblings\n>An `Array` of sibling `RObjects` for this object in Riak.  Defaults to `undefined`.\n\n##RObjects instance methods\n####RObject.save( _[callback]_ )\n###### // saves this RObject instance to Riak. Uses RObject's `.options` for the request if they exist.\n\n```javascript\nvar my_obj = riak.bucket('users').objects.new('my_key', { my_profile: \"Is Amazing!\" });\n\nmy_obj.save(function(err, obj) {\n    console.log(obj);\n});\n```\n\n####RObject.delete( _[callback]_ )\n###### // deletes this RObject instance from Riak. Uses RObject's `.options` for the request if they exist.\n\n```javascript\nmy_obj.delete(function(err, obj) {\n    console.log(obj);\n});\n```\n\n####RObject.fetch( _[resolver_fn], callback_ )\n###### // fetch/refresh object data from Riak and update this RObject's data, metadata, siblings.  Uses RObject's `.options` for the request if they exist.\n\n```javascript\nvar my_obj = riak.bucket('users').objects.new('my_key');\n\nmy_obj.fetch(function(err, obj) {\n    console.log(obj);\n});\n```\n\nNotice that this method can also take a custom [`resolver_fn`](#sibling-auto-resolution) in the event that reading updated data from Riak results in finding siblings.  If this isn't set it defaults to the resolver function on the `Bucket` instance that produced this `RObject`.\n\n####RObject.setMeta( _name, value_ )\n###### // set an X-Riak-Meta entry on this RObject.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.setMeta('extra', 'stuff can go here');  // sets metedata.meta.extra to 'stuff can go here' \n});\n```\n\n####RObject.getMeta( _name_ )\n###### // get an X-Riak-Meta entry to this RObject.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.getMeta('extra');  // will get the value of metedata.meta.extra    \n});\n```\n\n####RObject.removeMeta( _name_ )\n###### // remove an X-Riak-Meta entry from this RObject.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.removeMeta('extra');  // will delete metedata.meta.extra \n});\n```\n\n####RObject.addToIndex( _name, value_ )\n###### // add an X-Riak-Index entry to this RObject.\n\nThe `name` parameter sets the base name of the index.  The type, `_int` or `_bin`, of the index will be determined by the data type of `value`.  Anything passed into `value` that is an integer will be set in `metadata.index.name.int`, and anything else will be set in `metadata.index.name.bin`.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.addToIndex('things', 'apple');  // will add 'apple' to metadata.index.things.bin    \n    obj.addToIndex('counts', [2, 4, 6]);  // will add 2, 4, and 6 to metadata.index.counts.int\n});\n```\n\nIn the second example an `Array` of values was passed into the `value` parameter.  This will add all the values in the array to the named index.  All the values should be of the type in the array.\n\n\n####RObject.getIndex( _name_ )\n###### // get all values as an `Array` in an X-Riak-Index entry on this RObject.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.getIndex('things');  // value of metadata.index.things.bin or .int, whichever exists\n});\n```\n\n####RObject.removeFromIndex( _name, value_ )\n###### // remove a specific value from an X-Riak-Index entry on this RObject.\n\nJust like with the `.addToIndex()` method, the actual type of the underlying index will be determined based on the data type of the `value` you pass in.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.removeFromIndex('things', 'apple');  // removes 'apple' from metadata.index.things.bin\n});\n```\n\n####RObject.clearIndex( _name_ )\n###### // clears all values out of an X-Riak-Index entry on this RObject.\n\n```javascript\nriak.bucket('users').object.get('me', function(err, obj) {\n    obj.clearIndex('things');  // deletes metadata.index.things completely\n});\n```\n\n##Sibling Auto-Resolution\n\nBy default nodiak's Bucket class contains a client-side implementation of Last-Write-Wins for managing resolution.  It takes an array of sibling RObjects and returns the resolved sibling.  Implemented as follows:\n\n```javascript\nBucket.siblingLastWriteWins = function(siblings) {\n    function siblingLastModifiedSort(a, b) {\n        if(!a.metadata.last_modified || new Date(a.metadata.last_modified) < new Date(b.metadata.last_modified)) {\n            return 1;\n        }\n        else {\n            return -1;\n        }\n    }\n    siblings.sort(siblingLastModifiedSort);\n\n    return siblings[0];\n};\n```\n\nThe returned object then has the original set of siblings attached to it and is sent up to the user through a callback on the original `get` or `fetch` request.  This is true of bulk/batch operations as well.  Each RObject in the batch will be its resolved version with ***all*** its original siblings attached on a `.siblings` property.\n\nWhen you write your own auto-resolution functions they should conform to this spec, taking an `Array` of `RObjects` as input and returning a single resolved `RObject` as output.\n\nYou can provide your own auto-resolution functions either by overriding a Bucket instance's default resolver, like:\n\n```javascript\nvar my_bucket = riak.bucket('some_bucket');\n\nmy_bucket.resolver = function(conflicted_siblings) { \n    // If they don't shut-up you'll turn this car around!\n    var resolved = conflicted_siblings.pop();\n    \n    return resolved;\n};\n```\n\nand/or on every request for an object, like:\n\n\n```javascript\nvar my_resolver = function(conflicted_siblings) { \n    // If they don't shut-up you'll turn this car around!\n    var resolved = conflicted_siblings.pop();\n    \n    return resolved;\n};\n\nriak.bucket('some_bucket').object.get(['key1', 'key2'], my_resolver, function(err, r_objs) {\n    // Any RObject in the r_objs Array that had siblings will have been\n    // resolved using my_resolver, and will have it's originally siblings\n    // available through a .siblings property. \n});\n```\n\nThe RObject `.fetch()` method also accepts a user defined resolver function preceding the callback in its arguments list.  See the `RObject.fetch()` [documentation above](#robjectfetch-auto_resolver_fn-callback-) for details.\n\n> ***NOTE:*** \n\n> Additionally, the `Bucket` class has a `boolean` property `.getSiblingsSync` that controls the behavior of how siblings will be retrieved from Riak.  The default is `false` which will cause nodiak to make parallel async requests to get all the siblings at once.  If set to `true` then nodiak will attempt to retrieve all the siblings as a single large _'multipart/mixed'_ document.\n\n> The tradeoff is in the overhead in making lots and lots of smaller requests compared to one monolithic request.  The former can impact your network and cluster more negatively as it has to deal with the concurrent requests, but the latter also induces additionally time blocking while lots of data is being read and processed for a single request.\n\n\n##Riak Search and Riak 2i's\n\n####Bucket.search.solr( _query, callback_ )\n###### // perform a Riak Search operation and retrieve the standard Riak Search response object.\n\nThe `query` should be an `Object` containing properties that map to the URL query params specified in [Querying via the Solr Interface](http://wiki.basho.com/Riak-Search---Querying.html).  The `wt` parameter defaults to JSON.\n\n```javascript\nvar query = { \n    q: 'field1:been', \n    'q.op': 'and',\n    start: 25\n};\n\nriak.bucket('test').search.solr(query, true, function(err, response) {\n    console.log(response); \n});\n```\n\n>```javascript\n{\n    responseHeader: {\n        QTime: 54,\n        params: {\n            q: 'field1:been',\n            'q.op': 'or',\n            filter: '',\n            wt: 'json'\n        },\n        status: 0\n    },\n    response: {\n        maxScore: '0.353553',\n        numFound: 100,\n        start: 0,\n        docs: [\n            {\n                props: {},\n                index: 'test',\n                fields: {\n                    field1: 'has been set'\n                },\n                id: '11OAOmQHJmn9fcCfO5gPZatHdyL'\n            },\n            ...\n        ]\n    }\n}\n>```\n\n####Bucket.search.solr( _query_ ).stream( _callback_ )\n###### // perform a Riak Search operation and stream back the `docs` elements as `RObject`s\n\nJust as with the non-streaming version of this call, the `query` should be an `Object` containing properties that map to the URL query params specified in [Querying via the Solr Interface](http://wiki.basho.com/Riak-Search---Querying.html).  The `wt` parameter defaults to JSON.\n\n```javascript\nvar query = { \n    q: 'field1:been', \n    'q.op': 'and',\n    start: 25\n};\n\nvar compiled_results = [];\n\nriak.bucket('test').search.solr(query).stream(function(results) {\n    results.on('data', function(obj) {\n        compiled_results.push(obj);\n    });\n\n    results.on('error', function(err) {\n        console.warn(err);\n    });\n    \n    results.on('end', function() {\n        // we're all done fetching results.\n    });\n});\n```\n\nThis is simply provided as a convenience for when you know specifically that you want to fetch the actual objects in Riak referenced by the search result.\n\n\n####Bucket.search.twoi( _query, index, callback_ )\n###### // a 2i's range query that returns the list of matching keys.\n\nThe query format in nodiak for a 2i's search is an `Array` tuple containing the beginning and end of the range you want to search `['a','zzzzzzzzz']`, or just a scalar value when you want to do an exact match `'match_this'`.\n\nYou do not need to provide the `_int` or `_bin` suffix to the `index` name.  This is derived for you from the type of data you pass in to your query.  If the type is explicitly an integer `Number` then `_int` will be used, otherwise `_bin` will be automatically assumed. \n\n```javascript\nriak.bucket('test').search.twoi([0,10000], 'my_numbers', function(err, keys) {\n    console.log(keys);\n});\n```\n\nThe response will be an `Array` of the matching keys with the duplicates removed.  Riak by default adds a *key* to the matching set for every match, so if you have multiple entries in an index that match your query, then you'll get duplicate entries of that *key*  in the results.  If for some reason you need those duplicates then you can use the underlying backend adapter client directly.\n\n####Bucket.search.twoi( _query, index_ ).stream( _callback_ )\n###### // a 2i's range query that streams back the `RObjects` for the matched keys.\n\nvar compiled_results = [];\n\nriak.bucket('test').search.twoi([0,10000], 'my_numbers').stream(function(results) {\n    results.on('data', function(obj) {\n        compiled_results.push(obj);\n    });\n\n    results.on('error', function(err) {\n        console.warn(err);\n    });\n    \n    results.on('end', function() {\n        // we're all done fetching results.\n    });\n});\n\n##MapReduce\n\nMapReduce queries in nodiak are performed by chaining `map`, `link`, and `reduce` phases together on a set of `inputs` and then finally by running the chain using `execute`.\n\nEach of these phases, including the inputs conforms to the spec set forward by Basho in [their documentation](http://wiki.basho.com/Loading-Data-and-Running-MapReduce-Queries.html).\n\nAlso, nodiak allows you supply your own ad-hoc native functions as the `source` parameter on your `map` and `reduce` phase specifications.  If your phase has `'language' : 'javascript'` set, then it will simply convert your function to it's string source representation before attaching it to the `source` parameter.\n\nFor ad-hoc Erlang functions to work in Riak you have to add `{allow_strfun, true}` to the `riak_kv` section of your app.config files.  When send in a native Javascript function as the `source` parameter of your phase specification, and `'language' : 'erlang'` is set, then that native function must return from it a string representation of a valid Erlang MapReduce function. \n\n> ***NOTE:*** \n\n> Only use ad-hoc queries in development, they're slower and open up potential security risks compared to queries pre-deployed in your cluster.\n\n###client.mapred.inputs( _inputs, [include_data]_ )\n####.map( _phase_ ) .link( _phase_ ) .reduce( _phase_ )  .execute( _callback_ )\n###### // MapReduce w/ pre-aggregated results.\n\n```javascript\nriak.mapred.inputs([['a_bucket','key1'], ['b_bucket','key2']])\n    .map({\n        language: 'erlang',\n        module: 'riak_kv_mapreduce',\n        function: 'map_object_value',\n        arg: 'filter_notfound'})\n    \n    .reduce({\n        language: 'erlang',\n        module: 'riak_kv_mapreduce',\n        function: 'reduce_count_inputs'})     \n    \n    .execute(function(err, results) {\n        if(!err) console.log(results);\n    }\n);\n```\n####.execute( ).stream( _callback_ )\n###### // MapReduce w/ streaming results.\n\n```javascript\nvar compiled_results = [];\n\nriak.mapred.inputs('test')\n    .map({\n        language: 'erlang',\n        module: 'riak_kv_mapreduce',\n        function: 'map_object_value',\n        arg: 'filter_notfound'})\n    \n    .reduce({\n        language: 'erlang',\n        module: 'riak_kv_mapreduce',\n        function: 'reduce_count_inputs'})     \n    \n    .execute().stream(function(results) {\n        results.on('data', function(result) {\n            compiled_results.push(result);\n        });\n\n        results.on('end', function() {\n            console.log(compiled_results);\n        });\n\n        results.on('error', function(err) {\n            // Handle this however you like.\n        });\n    }\n);\n```\n\n>***NOTE:***\n\n>You can also pass an `Array` of `RObject`s into the `inputs` section of a MapReduce query.  Nodiak will automatically run through each object and convert the RObject into the `[bucket, key]` pairing that Riak expects.  Additionally, if you set `include_data` to `true` as the second `inputs` argument, then nodiak will also include the RObject's data, like `[bucket, key, data]`.\n\n\n# Tests\n\nThe test suite can be run by simply:\n\n    $ cd /path/to/nodiak\n    $ npm install -d\n    $ npm test\n\nThe suite expects to find Riak on an HTTP interface on port 8091 and an HTTPS interface on port 8071.  You can edit these values at the top of the `test/test.js` file to suit your environment.\n\n#Todos\n\n1. Add Link parsing and Link-Walking interfaces.\n\n2. Add a protobufs backend implementation.\n\n# License\n\n(The MIT License)\n\nCopyright (c) 2012 Coradine Aviation Systems\n\nCopyright (c) 2012 Nathan Aschbacher\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the 'Software'), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
  "_id": "nodiak@0.0.9",
  "_from": "nodiak"
}
